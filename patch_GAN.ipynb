{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdmvAWou5asD"
   },
   "outputs": [],
   "source": [
    "import speedup\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBwqhTuHTY4v"
   },
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = tf.keras.layers.Conv2D(n_filters, (3, 3),  activation='relu', kernel_initializer = \"he_normal\", padding=\"same\")(x)\n",
    "   x = tf.keras.layers.BatchNormalization()(x)\n",
    "   x = tf.keras.layers.Conv2D(n_filters, (3, 3),  activation='relu', kernel_initializer = \"he_normal\", padding=\"same\")(x)\n",
    "   x = tf.keras.layers.BatchNormalization()(x)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF3OppL0UcFp"
   },
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = tf.keras.layers.MaxPool2D((2, 2))(f)\n",
    "   return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN_5xuYkUm2E"
   },
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "   x = tf.keras.layers.Conv2DTranspose(n_filters, (3, 3), (2, 2), padding=\"same\")(x)\n",
    "   x = tf.keras.layers.concatenate([x, conv_features])\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awNeMTdAUEYo"
   },
   "outputs": [],
   "source": [
    "imageSize = 512\n",
    "m = 3\n",
    "\n",
    "def Generator():\n",
    "    inputs = tf.keras.Input(shape=(imageSize, imageSize, m))\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "    outputs = tf.keras.layers.Conv2D(3, (1, 1), activation='sigmoid', padding = \"same\")(u9)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESq9o2_CadIn"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  inp = tf.keras.Input(shape=(imageSize, imageSize, m), name='input_image')\n",
    "  tar = tf.keras.Input(shape=(imageSize, imageSize, m), name='target_image')\n",
    "  x = tf.keras.layers.concatenate([inp, tar])\n",
    "\n",
    "  f1, p1 = downsample_block(x, 32)\n",
    "  f2, p2 = downsample_block(p1, 64)\n",
    "  f3, p3 = downsample_block(p2, 128)\n",
    "  \n",
    "  outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', kernel_initializer = \"he_normal\", padding=\"same\")(p3)\n",
    "\n",
    "  return tf.keras.Model([inp, tar], outputs, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLoTQScKX4u_"
   },
   "outputs": [],
   "source": [
    "image_path = '/content/drive/MyDrive/source2'\n",
    "models_path = '/content/drive/MyDrive/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYo1vlvITGZz"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = bce(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = bce(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = bce(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  seg_loss = bce(target, gen_output)\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * seg_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, seg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39oUpeHXYIH2"
   },
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "\n",
    "    def compile(self, discriminator_optimizer, generator_optimizer, discriminator_loss, generator_loss):\n",
    "        super(GAN, self).compile()\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.discriminator_loss = discriminator_loss\n",
    "        self.generator_loss = generator_loss\n",
    "\n",
    "    def call(self, data, training=False):\n",
    "        pass\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "      input_image, target_image = data\n",
    "\n",
    "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generator_output = self.generator(input_image)\n",
    "        discriminator_real_output = self.discriminator([input_image, target_image])\n",
    "        discriminator_generated_output = self.discriminator([input_image, generator_output])\n",
    "                                                              \n",
    "        gen_total_loss, gen_gan_loss, gen_seg_loss = self.generator_loss(discriminator_generated_output, generator_output, target_image)\n",
    "        disc_loss = self.discriminator_loss(discriminator_real_output, discriminator_generated_output)\n",
    "      \n",
    "      generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          self.generator.trainable_variables)\n",
    "      discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                          self.discriminator.trainable_variables)\n",
    "\n",
    "      self.generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          self.generator.trainable_variables))\n",
    "      self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              self.discriminator.trainable_variables))\n",
    "      return {\"generator_loss\": gen_total_loss, \"discriminator_loss\": disc_loss, \"gan_loss\": gen_gan_loss, \"seg_loss\": gen_seg_loss}\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "\n",
    "      input_image, target_image = data\n",
    "\n",
    "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generator_output = self.generator(input_image)\n",
    "        discriminator_real_output = self.discriminator([input_image, target_image])\n",
    "        discriminator_generated_output = self.discriminator([input_image, generator_output])\n",
    "                                                              \n",
    "        gen_total_loss, gen_gan_loss, gen_seg_loss = self.generator_loss(discriminator_generated_output, generator_output, target_image)\n",
    "        disc_loss = self.discriminator_loss(discriminator_real_output, discriminator_generated_output)\n",
    "        \n",
    "      generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          self.generator.trainable_variables)\n",
    "      discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                          self.discriminator.trainable_variables)\n",
    "\n",
    "      self.generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          self.generator.trainable_variables))\n",
    "      self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              self.discriminator.trainable_variables))\n",
    "      return {\"generator_loss\": gen_total_loss, \"discriminator_loss\": disc_loss}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUUhfYyC77WI",
    "outputId": "cf55efed-61f0-4c4c-c838-35adfb8baa62"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from speedup import generate_out_images3\n",
    "import numpy as np\n",
    "from random import randint, uniform\n",
    "import imageio\n",
    "import time\n",
    "\n",
    "\n",
    "source_num = 2799\n",
    "dim = 512\n",
    "stationary_defocus = 0.05\n",
    "\n",
    "\n",
    "def gen():\n",
    "    while True:\n",
    "        layer1_number = randint(0, source_num)\n",
    "        layer2_number = randint(0, source_num)\n",
    "        layer3_number = randint(0, source_num)\n",
    "\n",
    "        src1 = imageio.imread(image_path + '/image' + str(layer1_number).zfill(4) + '.png')\n",
    "        src2 = imageio.imread(image_path + '/image' + str(layer2_number).zfill(4) + '.png')\n",
    "        src3 = imageio.imread(image_path + '/image' + str(layer3_number).zfill(4) + '.png')\n",
    "        src = np.zeros((dim, dim, m), np.double)\n",
    "        src[:, :, 0] = src1[:, :, 0]\n",
    "        src[:, :, 1] = src2[:, :, 0]\n",
    "        src[:, :, 2] = src3[:, :, 0]\n",
    "        src = src - np.amin(src)\n",
    "        src = src / np.amax(src)\n",
    "\n",
    "        w = uniform(0.05, 0.5) \n",
    "        \n",
    "        a_10 = uniform(-1e3, 1e3)\n",
    "        a_01 = uniform(-1e3, 1e3)\n",
    "        b_20 = uniform(1, 1.5)\n",
    "        b_11 = uniform(-0.1, 0.1)\n",
    "        b_02 = uniform(1, 1.5)\n",
    "        c_30 = uniform(-1.5e-6, 1.5e-6)\n",
    "        c_21 = uniform(-2e-6, 2e-6)\n",
    "        c_12 = uniform(-2e-6, 2e-6)\n",
    "        c_03 = uniform(-1.5e-6, 1.5e-6)\n",
    "\n",
    "        out = generate_out_images3(dim, m, w, stationary_defocus, a_10, a_01, b_20, b_11, b_02, c_30, c_21, c_12, c_03, src)[1]\n",
    "\n",
    "        out = out / np.amax(out)\n",
    "\n",
    "        src[src > 0] = 1.\n",
    "\n",
    "        yield (out, src)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "tr_dataset = tf.data.Dataset.from_generator(\n",
    "     gen, (tf.float64, tf.float64), (tf.TensorShape([dim, dim, m]), tf.TensorShape([dim, dim, m])))\\\n",
    "    .batch(batch_size=1).prefetch(buffer_size=8)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "     gen, (tf.float64, tf.float64), (tf.TensorShape([dim, dim, m]), tf.TensorShape([dim, dim, m])))\\\n",
    "    .take(count=64).cache().batch(batch_size=1)\n",
    "\n",
    "metric = 'val_generator_loss'\n",
    "save_best_callback = tf.keras.callbacks.ModelCheckpoint(models_path + 'bestmodel_gan.hdf5',\n",
    "                                                        save_weights_only=True, save_best_only=True, verbose=True, monitor = metric)\n",
    "csv_logger_callback = tf.keras.callbacks.CSVLogger(models_path + 'log_gan.csv')\n",
    "#generator_lr_reduce_callback = CustomReduceLRoP(factor=0.5, min_delta=5e-4, patience=5, monitor = 'val_generator_loss', optim_lr = generator_optimizer)\n",
    "#discriminator_lr_reduce_callback = CustomReduceLRoP(factor=0.5, min_delta=5e-4, patience=5, monitor = 'val_discriminator_loss', optim_lr = discriminator_optimizer)\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=25, monitor = metric)\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "#generator.load_weights(models_path + 'bestmodel_unet2d_fix_def.hdf5')\n",
    "model_instance = GAN(discriminator, generator)\n",
    "model_instance.compile(discriminator_optimizer=discriminator_optimizer,\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_loss = discriminator_loss,\n",
    "        generator_loss = generator_loss, )\n",
    "\n",
    "model_instance.fit(x=tr_dataset, validation_data=val_dataset, verbose=1, validation_steps=64,\n",
    "                   steps_per_epoch=256, epochs=30,\n",
    "                   callbacks=[save_best_callback, csv_logger_callback, early_stop_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
